{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt  \n",
    "\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "movies_with_customer_ratings_loaded = pd.read_csv('../dataset/prepared/movies_with_customer_ratings_and_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = movies_with_customer_ratings_loaded.head(6000000)\n",
    "del movies_with_customer_ratings_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Budget', 'Genre', 'Original_language', 'Runtime','Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = dataset[['MovieID','Title']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_customers = dataset.CustomerID.nunique()\n",
    "print(\"Number of customers: \", n_customers)\n",
    "n_movies = dataset.MovieID.nunique()\n",
    "print(\"Number of movies: \", n_movies)\n",
    "print(\"Number of elements in matrix: \", n_customers * n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into traing and test set\n",
    "\n",
    "customers = dataset.CustomerID.unique()\n",
    "movies = dataset.MovieID.unique()\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "#test_dataset = pd.DataFrame(columns=dataset.columns)\n",
    "#train_dataset = pd.DataFrame(columns=dataset.columns)\n",
    "\n",
    "#counter = 1\n",
    "#for customer in customers:\n",
    "#    temp = dataset[dataset['CustomerID'] == customer]\n",
    "#    \n",
    "#    temp_train, temp_test = train_test_split(temp, test_size=0.35)\n",
    "#    \n",
    "#    test_dataset = pd.concat([test_dataset, temp_test])\n",
    "#    train_dataset = pd.concat([train_dataset, temp_train])\n",
    "#    print(counter)\n",
    "#    counter += 1\n",
    "\n",
    "#train_dataset.to_csv('../dataset/prepared/svd/train_test/train_dataset.csv', encoding='utf-8')\n",
    "#test_dataset.to_csv('../dataset/prepared/svd/train_test/test_dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test dataset shape: \", test_dataset.shape)\n",
    "print(\"Train dataset shape: \", train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.drop(['Title', 'year_of_rating', 'month_of_rating', 'day_of_rating', 'YearOfRelease'], axis=1)\n",
    "test_dataset = test_dataset.drop(['Title', 'year_of_rating', 'month_of_rating', 'day_of_rating', 'YearOfRelease'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_df = train_dataset.pivot(index = 'CustomerID', columns='MovieID', values='Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(train_matrix, k, store_parameters_to_csv=False):\n",
    "    utilit_matrix = np.array(train_matrix)\n",
    "    \n",
    "    mask = np.isnan(utilit_matrix)\n",
    "    masked_arr = np.ma.masked_array(utilit_matrix, mask)\n",
    "    item_means = np.mean(masked_arr, axis=0)\n",
    "    \n",
    "    utilit_matrix = masked_arr.filled(item_means)\n",
    "    \n",
    "    x = np.tile(item_means, (utilit_matrix.shape[0],1))\n",
    "    utilit_matrix = utilit_matrix - x\n",
    "    U, s, V = np.linalg.svd(utilit_matrix, full_matrices=False)\n",
    "    del utilit_matrix\n",
    "    s=np.diag(s)\n",
    "    \n",
    "    #We keep only the most significant features\n",
    "    s = s[0:k,0:k]\n",
    "    U = U[:,0:k]\n",
    "    V = V[0:k,:]\n",
    "    \n",
    "    s_root = sqrtm(s)\n",
    "    \n",
    "    Usk = np.dot(U,s_root)\n",
    "    skV = np.dot(s_root,V)\n",
    "    UsV = np.dot(Usk, skV)\n",
    "    \n",
    "    UsV = UsV + x\n",
    "    \n",
    "    print(\"Finished SVD\")\n",
    "    return UsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "UsV = svd(train_matrix_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = []\n",
    "customer = 42\n",
    "movie = 187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A_df.as_matrix()\n",
    "user_ratings_mean = np.mean(A, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_mean = np.mean(A, axis=1)\n",
    "A_demeaned = A - user_ratings_mean.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "U, S, Vt = svds(A_demeaned, k=50\n",
    "S = np.diag(S))\n",
    "print(\"U-shape: \", U.shape)\n",
    "print(\"S-shape: \", S.shape)\n",
    "print(\"Vt-shape: \", Vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy import savetxt\n",
    "#savetxt('../dataset/prepared/svd/parameters/u.csv', U, delimiter=',')\n",
    "#savetxt('../dataset/prepared/svd/parameters/s.csv', S, delimiter=',')\n",
    "#savetxt('../dataset/prepared/svd/parameters/vt.csv', Vt, delimiter=',')\n",
    "#savetxt('../dataset/prepared/svd/parameters/user_ratings_mean.csv', user_ratings_mean, delimiter=',')\n",
    "#savetxt('../dataset/prepared/svd/parameters/columns.csv', A_df.columns, delimiter=',')\n",
    "#savetxt('../dataset/prepared/svd/parameters/index.csv', A_df.index, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make it work with limited amount of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U = loadtxt('../dataset/prepared/svd/parameters/u.csv', delimiter=',')\n",
    "#S = loadtxt('../dataset/prepared/svd/parameters/s.csv', delimiter=',')\n",
    "#Vt = loadtxt('../dataset/prepared/svd/parameters/vt.csv', delimiter=',')\n",
    "#user_ratings_mean = loadtxt('../dataset/prepared/svd/parameters/user_ratings_mean.csv', delimiter=',')\n",
    "#columns = loadtxt('../dataset/prepared/svd/parameters/columns.csv', delimiter=',')\n",
    "#index = loadtxt('../dataset/prepared/svd/parameters/index.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_predicted_ratings = np.dot(np.dot(U,S), Vt) + user_ratings_mean.reshape(-1,1)\n",
    "predictions_df = pd.DataFrame(all_users_predicted_ratings, columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = 42\n",
    "predictions_spesific_user = predictions_df.loc[predictions_df.index == customer]\n",
    "predictions_spesific_user_sorted = predictions_spesific_user.sort_values(by=customer, ascending=False, axis=1)\n",
    "ratings_spesific_user = A_df.loc[A_df.index == customer]\n",
    "ratings_spesific_user_sorted = ratings_spesific_user.sort_values(by=customer, ascending=False, axis=1)\n",
    "#If you liked these movies - \n",
    "top_rated_movies = list(ratings_spesific_user_sorted.columns)[:10]\n",
    "print(top_rated_movies)\n",
    "#You will probably like these movies -\n",
    "predicted_movies = list(predictions_spesific_user_sorted.columns)\n",
    "top_predicted_movies = list()\n",
    "for movie in predicted_movies:\n",
    "    if(movie not in top_rated_movies):\n",
    "        top_predicted_movies.append(movie)\n",
    "top_predicted_movies = top_predicted_movies[:10]\n",
    "print(top_predicted_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users 610\n",
      "Number of movies 9724\n",
      "  userId movieId  rating  timestamp\n",
      "0      1       1     4.0  964982703\n",
      "1      1       3     4.0  964981247\n",
      "2      1       6     4.0  964982224\n",
      "3      1      47     5.0  964983815\n",
      "4      1      50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('../dataset/ml-latest-small/ratings.csv')\n",
    "data['userId'] = data['userId'].astype('str')\n",
    "data['movieId'] = data['movieId'].astype('str')\n",
    "users = data['userId'].unique() #list of all users\n",
    "movies = data['movieId'].unique() #list of all movies\n",
    "print(\"Number of users\", len(users))\n",
    "print(\"Number of movies\", len(movies))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torsteml/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  if sys.path[0] == '':\n",
      "/home/torsteml/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "test = pd.DataFrame(columns=data.columns)\n",
    "train = pd.DataFrame(columns=data.columns)\n",
    "test_ratio = 0.2 #fraction of data to be used as test set.\n",
    "for u in users:\n",
    "    temp = data[data['userId'] == u]\n",
    "    n = len(temp)\n",
    "    test_size = int(test_ratio*n)\n",
    "temp = temp.sort_values('timestamp').reset_index()\n",
    "temp.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "dummy_test = temp.ix[n-1-test_size :]\n",
    "dummy_train = temp.ix[: n-2-test_size]\n",
    "    \n",
    "test = pd.concat([test, dummy_test])\n",
    "train = pd.concat([train, dummy_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import sqrtm\n",
    "def create_utility_matrix(data, formatizer = {'user':0, 'item': 1, 'value': 2}):\n",
    "    \"\"\"\n",
    "        :param data:      Array-like, 2D, nx3\n",
    "        :param formatizer:pass the formatizer\n",
    "        :return:          utility matrix (n x m), n=users, m=items\n",
    "    \"\"\"\n",
    "        \n",
    "    itemField = formatizer['item']\n",
    "    userField = formatizer['user']\n",
    "    valueField = formatizer['value']\n",
    "    userList = data.ix[:,userField].tolist()\n",
    "    itemList = data.ix[:,itemField].tolist()\n",
    "    valueList = data.ix[:,valueField].tolist()\n",
    "    users = list(set(data.ix[:,userField]))\n",
    "    items = list(set(data.ix[:,itemField]))\n",
    "    users_index = {users[i]: i for i in range(len(users))}\n",
    "    pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\n",
    "    for i in range(0,len(data)):\n",
    "        item = itemList[i]\n",
    "        user = userList[i]\n",
    "        value = valueList[i]\n",
    "    pd_dict[item][users_index[user]] = value\n",
    "    X = pd.DataFrame(pd_dict)\n",
    "    X.index = users\n",
    "        \n",
    "    itemcols = list(X.columns)\n",
    "    items_index = {itemcols[i]: i for i in range(len(itemcols))}\n",
    "    # users_index gives us a mapping of user_id to index of user\n",
    "    # items_index provides the same for items\n",
    "    return X, users_index, items_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(train, k):\n",
    "    utilMat = np.array(train)\n",
    "    # the nan or unavailable entries are masked\n",
    "    mask = np.isnan(utilMat)\n",
    "    masked_arr = np.ma.masked_array(utilMat, mask)\n",
    "    item_means = np.mean(masked_arr, axis=0)\n",
    "    # nan entries will replaced by the average rating for each item\n",
    "    utilMat = masked_arr.filled(item_means)\n",
    "    x = np.tile(item_means, (utilMat.shape[0],1))\n",
    "    # we remove the per item average from all entries.\n",
    "    # the above mentioned nan entries will be essentially zero now\n",
    "    utilMat = utilMat - x\n",
    "    # The magic happens here. U and V are user and item features\n",
    "    U, s, V=np.linalg.svd(utilMat, full_matrices=False)\n",
    "    s=np.diag(s)\n",
    "    # we take only the k most significant features\n",
    "    s=s[0:k,0:k]\n",
    "    U=U[:,0:k]\n",
    "    V=V[0:k,:]\n",
    "    s_root=sqrtm(s)\n",
    "    Usk=np.dot(U,s_root)\n",
    "    skV=np.dot(s_root,V)\n",
    "    UsV = np.dot(Usk, skV)\n",
    "    UsV = UsV + x\n",
    "    print(\"svd done\")\n",
    "    return UsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torsteml/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "/home/torsteml/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/torsteml/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n",
      "/home/torsteml/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "/home/torsteml/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svd done\n",
      "svd done\n",
      "svd done\n",
      "svd done\n",
      "svd done\n",
      "0.9837164750957854\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rmse(true, pred):\n",
    "    # this will be used towards the end\n",
    "    x = true - pred\n",
    "    return sum([xi*xi for xi in x])/len(x)\n",
    "# to test the performance over a different number of features\n",
    "no_of_features = [8]\n",
    "utilMat, users_index, items_index = create_utility_matrix(train)\n",
    "for f in no_of_features: \n",
    "    svdout = svd(utilMat, k=f)\n",
    "    pred = [] #to store the predicted ratings\n",
    "    for _,row in test.iterrows():\n",
    "        user = row['userId']\n",
    "        item = row['movieId']\n",
    "        u_index = users_index[user]\n",
    "        if item in items_index:\n",
    "            i_index = items_index[item]\n",
    "            pred_rating = svdout[u_index, i_index]\n",
    "        else:\n",
    "            pred_rating = np.mean(svdout[u_index, :])\n",
    "        pred.append(pred_rating)\n",
    "print(rmse(test['rating'], pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
